{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"ai/context-engineering/","title":"Context Engineering","text":""},{"location":"ai/context-engineering/#what-is-context-engineering","title":"What is Context Engineering?","text":"<p>Context engineering is the practice of designing, curating, and managing the information and metadata provided to AI systems to optimize their performance, reliability, and safety. While prompt engineering focuses on how you ask, context engineering focuses on what the AI knows and how it receives that knowledge.</p>"},{"location":"ai/context-engineering/#why-is-context-important","title":"Why is Context Important?","text":"<ul> <li>Improves relevance and accuracy: Supplying the right context helps the AI generate more precise and useful responses.</li> <li>Reduces ambiguity: Clear background information minimizes misunderstandings.</li> <li>Mitigates hallucinations: Proper context can prevent the AI from making up facts or going off-topic.</li> <li>Enables personalization: Context allows tailoring responses to specific users, domains, or tasks.</li> </ul>"},{"location":"ai/context-engineering/#types-of-context","title":"Types of Context","text":"<ul> <li>Static Context: Background information that remains constant during a session (e.g., company policies, product documentation).</li> <li>Dynamic Context: Information that changes during interaction (e.g., conversation history, user preferences, recent actions).</li> <li>External Context: Data fetched from APIs, databases, or external knowledge sources in real time.</li> <li>Implicit Context: Inferred information, such as user intent or emotional tone.</li> </ul>"},{"location":"ai/context-engineering/#principles-of-effective-context-engineering","title":"Principles of Effective Context Engineering","text":"<ul> <li>Relevance: Only provide information that is necessary for the task.</li> <li>Clarity: Structure context clearly\u2014use sections, bullet points, or tables as needed.</li> <li>Recency: Keep dynamic context up to date.</li> <li>Consistency: Maintain consistent terminology and formatting.</li> <li>Security &amp; Privacy: Avoid including sensitive or unnecessary personal data.</li> </ul>"},{"location":"ai/context-engineering/#example-context-engineering-in-action","title":"Example: Context Engineering in Action","text":"<p>Suppose you are building an AI assistant for customer support: - Static Context: Product manuals, support policies - Dynamic Context: Current customer\u2019s order status, recent chat history - External Context: Live inventory data, shipping estimates</p> <p>Prompt Example: <pre><code>[Context]\nCustomer: Jane Doe\nOrder #: 12345\nProduct: Widget X\nIssue: \"My widget won't turn on.\"\n\n[Task]\nProvide troubleshooting steps and offer to escalate if unresolved.\n</code></pre></p>"},{"location":"ai/context-engineering/#related-topics","title":"Related Topics","text":"<ul> <li>Prompt Engineering</li> <li>Types of Prompts</li> <li>Model Context Protocols</li> </ul>"},{"location":"ai/prompt-engineering/","title":"Prompt Engineering","text":""},{"location":"ai/prompt-engineering/#what-is-a-prompt","title":"What is a Prompt?","text":"<ul> <li>Structuring inputs (questions or commands) to guide an AI model to produce accurate and relevant output.</li> <li>Helps reduce hallucinations, bias, and vague answers.</li> <li>Useful for anyone working with AI: developers, researchers, content creators, and more.</li> </ul>"},{"location":"ai/prompt-engineering/#types-of-prompts","title":"Types of Prompts","text":"<p>There are several common types of prompts used with AI language models:</p> <ul> <li>Zero-shot Prompting: Give the model a task without examples.</li> <li>Few-shot Prompting: Show the model a few examples to guide its responses.</li> <li>Chain-of-thought Prompting: Ask the model to reason step-by-step.</li> <li>Instruction-based Prompting: Provide clear, structured instructions.</li> <li>Role-based Prompting: Assign a role or persona to the model.</li> <li>Contextual or Dynamic Prompting: Insert relevant background/context before the question.</li> <li>Multi-turn Prompting: Build context across a conversation.</li> <li>Prompt Chaining (Modular Prompting): Break tasks into smaller steps, using outputs as new inputs.</li> </ul> <p>For detailed definitions and examples, see Types of Prompts.</p>"},{"location":"ai/prompt-engineering/#why-prompt-engineering-matters","title":"Why Prompt Engineering Matters","text":"<p>Prompt engineering means crafting prompts to guide AI models. The main goals:</p> <ul> <li>Improve accuracy and relevance of responses</li> <li>Minimize hallucinations (false information)</li> <li>Reduce ambiguity in instructions</li> <li>Encourage creative or insightful results when needed</li> </ul>"},{"location":"ai/prompt-engineering/#principles-of-good-prompt-engineering","title":"Principles of Good Prompt Engineering","text":"<p>Use these principles for better prompts:</p> <ul> <li>Clarity: Be specific and unambiguous.</li> <li>Context: Give background if needed.</li> <li>Structure: Use lists or clear formatting.</li> <li>Examples: Show what you want the AI to produce.</li> <li>Role Play: Ask the AI to act as an expert or persona if helpful.</li> </ul>"},{"location":"ai/prompt-engineering/#tips-for-better-prompts","title":"Tips for Better Prompts","text":"<ol> <li> <p>Be clear and specific </p> <p>Bad: \"Tell me about plants.\" Good: \"What are the benefits of growing lettuce in a hydroponic NFT system indoors?\"</p> <p>Include relevant context, constraints, or goals in your prompt.</p> <p></p> </li> <li> <p>Provide a role or perspective (optional but powerful) </p> <p>\"Act as a data scientist. Can you explain how to fine-tune a transformer model using PyTorch?\"  </p> <p>This helps the AI simulate a more accurate tone or specialist mindset.</p> <p></p> </li> <li> <p>Break complex queries into steps </p> <p>\"I want to write a research paper. First, help me outline the key sections, then we can work on each section together.\"  </p> <p>Chunking improves focus and minimizes confusion.</p> <p></p> </li> <li> <p>Set the format you want </p> <p>\"Give me a bullet-point summary.\" \"Write it as a table with columns: Feature | Description | Pros | Cons.\"  </p> <p>This keeps answers structured and easy to digest.</p> <p></p> </li> <li> <p>Use examples for clarification </p> <p>\"I want my writing to sound like this: 'The sunset poured gold over the quiet hills.' Can you improve my paragraph to match that style?\"  </p> <p>Examples reduce hallucination and improve alignment with your intention.</p> <p></p> </li> <li> <p>Specify what you don't want </p> <p>\"Don't include historical background \u2014 just focus on current applications of AI in healthcare.\"  </p> <p>This prevents unnecessary or off-topic output.</p> <p></p> </li> <li> <p>Iterate and refine </p> <p>Ask, review, then say: \"This is close, but could you make it more formal / concise / technical?\"  </p> <p>You don't have to get the perfect prompt the first time \u2014 interactive refinement is key.</p> </li> </ol>"},{"location":"ai/prompt-engineering/#pitfalls-to-avoid","title":"Pitfalls to Avoid","text":"Common Issue How to Fix Too vague Add details or constraints Unclear task Explain expected output Overly long Break into steps"},{"location":"ai/prompt-engineering/#improving-your-prompts","title":"Improving Your Prompts","text":"<p>Prompt engineering is experimental. You may need to:</p> <ul> <li>Rewrite from a new perspective</li> <li>Add constraints (e.g., word count, tone)</li> <li>Remove extra context</li> </ul> <p>Test and revise your prompts for best results.</p>"},{"location":"ai/prompt-engineering/#further-tips","title":"Further Tips","text":"<ul> <li>Use markdown formatting to structure prompts and outputs.</li> <li>Chain prompts: use one output as input for the next task.</li> <li>Ask the AI to explain its reasoning if you need clarity.</li> </ul>"},{"location":"ai/prompt-engineering/#example-transformation","title":"Example Transformation","text":"Type Prompt Example Too vague \"Tell me about AI\" Better \"Explain how AI is used in fraud detection in financial institutions.\" Best \"Act as a security engineer.Explain how machine learning helps detect fraud in banking systems,including common algorithms and real-world challenges.\""},{"location":"ai/prompt-engineering/#how-to-reduce-hallucinations","title":"How to Reduce Hallucinations","text":"<ul> <li>Ask for sources, assumptions, or step-by-step reasoning.</li> <li>Example: \"Can you give me a step-by-step explanation of how you arrived at this answer?\"</li> <li>Request external verification if accuracy is critical.</li> <li>Avoid vague or open-ended questions unless you're brainstorming.</li> </ul>"},{"location":"ai/prompt-engineering/#related-topics","title":"Related Topics","text":"<ul> <li>AI Hallucination</li> <li>Few-shot Learning</li> <li>Zero-shot Prompting</li> <li>Chain-of-Thought Prompting</li> </ul>"},{"location":"ai/prompt-engineering/#references","title":"References","text":"<ul> <li>OpenAI Cookbook: Prompt Engineering</li> <li>DeepLearning.AI: Prompt Engineering Guide</li> <li>Google: Prompt Design</li> <li>Prompt Engineering for AI Agents</li> </ul>"},{"location":"ai/types-of-prompts/","title":"Types of Prompts","text":"<p>This page describes common types of prompts used with AI language models. Each type includes a definition, example, and when to use it.</p>"},{"location":"ai/types-of-prompts/#1-zero-shot-prompting","title":"1. Zero-shot Prompting","text":"<p>Ask the model to perform a task without providing any examples.</p> <p>Use: Simple or well-known tasks.</p> <p>Example </p> <p>Q: Translate this sentence into French: I love pizza. A: J'adore la pizza.</p>"},{"location":"ai/types-of-prompts/#2-few-shot-prompting","title":"2. Few-shot Prompting","text":"<p>Show a handful of examples to illustrate the desired pattern or response.</p> <p>Use: To guide the model with patterns.</p> <p>Example </p> <p>Q: Translate into French: \u2013 I love pizza. \u2192 J'adore la pizza. \u2013 She is happy. \u2192 Elle est heureuse. \u2013 He is tired. \u2192 A: Il est fatigu\u00e9.</p>"},{"location":"ai/types-of-prompts/#3-chain-of-thought-prompting","title":"3. Chain-of-thought Prompting","text":"<p>Encourage the model to reason through problems step-by-step and make its thinking process explicit.</p> <p>Use: Math, logic, and complex reasoning.</p> <p>Example </p> <p>Q: If a train leaves the station at 3 PM and travels for 2 hours, what time does it arrive? Let's think step by step. A: The train leaves at 3 PM. It travels for 2 hours. 3 PM plus 2 hours is 5 PM. So, the train arrives at 5 PM.</p> <p>Use: Math, logic, and complex reasoning.</p>"},{"location":"ai/types-of-prompts/#4-instruction-based-prompting","title":"4. Instruction-based Prompting","text":"<p>Give clear, structured directions for the model to follow.</p> <p>Use: For high precision or consistent format.</p> <p>Example </p> <p>Q: Summarize this paragraph in 2 sentences focusing only on the main idea. A: The paragraph discusses the importance of teamwork in achieving goals. It emphasizes that collaboration leads to better results than working alone.</p> <p>Use: For high precision or consistent format.</p>"},{"location":"ai/types-of-prompts/#5-role-based-prompting","title":"5. Role-based Prompting","text":"<p>Assign a specific role or persona to shape the response style or expertise.</p> <p>Use: To match tone, expertise, or audience.</p> <p>Example </p> <p>Q: You are a professional lawyer. Explain this legal term in simple language: \"Habeas Corpus\". A: \"Habeas Corpus\" is a legal term that means a person has the right to be brought before a judge if they are being held in jail, to make sure their detention is lawful.</p> <p>Use: To match tone, expertise, or audience.</p>"},{"location":"ai/types-of-prompts/#6-contextual-or-dynamic-prompting","title":"6. Contextual or Dynamic Prompting","text":"<p>Provide relevant background information or context before asking the main question.</p> <p>Use: When the task depends heavily on prior information.</p> <p>Example </p> <p>Q: In the context of European history during the 19th century, explain the causes of the French Revolution. A: The French Revolution was caused by social inequality, economic hardship, and the influence of Enlightenment ideas, which led people to demand more rights and a fairer government.</p> <p>Use: When the task depends heavily on prior information.</p>"},{"location":"ai/types-of-prompts/#7-multi-turn-prompting","title":"7. Multi-turn Prompting","text":"<p>What it is: Building context across a conversation.</p> <p>Example </p> <p>Q: (Turn 1) Imagine you are a travel agent. I want to visit Italy. A: (Turn 1) That sounds wonderful! What cities in Italy are you interested in visiting? Q: (Turn 2) I'm interested in Rome and Venice. What are the must-see attractions? A: (Turn 2) In Rome, you should visit the Colosseum, the Vatican, and the Trevi Fountain. In Venice, don't miss St. Mark's Basilica, the Grand Canal, and a gondola ride.</p> <p>Use: For dialogue, memory-based reasoning, tutoring, etc.</p>"},{"location":"ai/types-of-prompts/#8-prompt-chaining-modular-prompting","title":"8. Prompt Chaining (Modular Prompting)","text":"<p>What it is: Breaking tasks into smaller steps and using the output of one as the input of the next.</p> <p>Example </p> <p>Q (Step 1): Extract all dates from this text: \"The conference was held on March 3, 2022, and the next meeting is scheduled for July 15, 2023.\" A (Step 1): March 3, 2022; July 15, 2023 Q (Step 2): For each date, summarize the event that happened. A (Step 2): - March 3, 2022: The conference was held. - July 15, 2023: The next meeting is scheduled.</p> <p>Use: For complex tasks like code generation, document parsing, etc. </p>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/","title":"Sample AI Application with MCP","text":""},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#1-what-is-mcp-model-context-protocol","title":"1. What is MCP (Model Context Protocol)?","text":"<p>MCP stands for Model Context Protocol. It is an open protocol designed to standardize how AI models, tools, and agents communicate, share context, and interoperate. MCP enables: - Interoperability: Different AI models and tools can work together seamlessly. - Context Sharing: Models can share and access context (like conversation history, user preferences, etc.). - Extensibility: Easy integration of new tools, models, or agents.</p> <p>Use Cases: - Building AI assistants that can use multiple models/tools. - Creating agent frameworks where tools and models can be swapped or extended. - Standardizing prompt and context management across AI applications.</p>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#2-what-is-the-mcp-python-sdk","title":"2. What is the MCP Python SDK?","text":"<p>The MCP Python SDK is a library that implements the MCP protocol in Python. It provides: - APIs to build MCP-compliant servers (model/tool providers) and clients (applications/agents). - Utilities for context management, prompt formatting, and tool/resource registration. - Example implementations for quick start.</p> <p>Here is a link to the MCP Python SDK.</p>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#3-how-to-install-the-mcp-python-sdk","title":"3. How to Install the MCP Python SDK","text":""},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#a-prerequisites","title":"a. Prerequisites","text":"<ul> <li>Python 3.8+</li> <li>uv</li> </ul>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#b-installation","title":"b. Installation","text":"<pre><code>uv add \"mcp[cli]\"\nor\ngit clone https://github.com/modelcontextprotocol/python-sdk.git\n</code></pre>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#c-running-the-standalone-mcp-development-tools","title":"c. Running the standalone MCP development tools","text":"<pre><code>uv run mcp\n</code></pre>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#4-example-running-an-mcp-server-and-client","title":"4. Example: Running an MCP Server and Client","text":""},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#a-example-mcp-server","title":"a. Example MCP Server","text":"<p>A server provides a model or tool via MCP.</p> <p>server.py <pre><code>from mcp_sdk.server import MCPServer\nfrom mcp_sdk.resources import TextCompletionResource\n\nclass EchoResource(TextCompletionResource):\n    def complete(self, prompt, context):\n        return f\"Echo: {prompt}\"\n\nserver = MCPServer(resources=[EchoResource()])\nserver.run(host=\"0.0.0.0\", port=8000)\n</code></pre></p> <p>Run the server: <pre><code>python server.py\n</code></pre></p>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#b-example-mcp-client","title":"b. Example MCP Client","text":"<p>A client connects to an MCP server and uses its resources.</p> <p>client.py <pre><code>from mcp_sdk.client import MCPClient\n\nclient = MCPClient(\"http://localhost:8000\")\nresponse = client.complete(prompt=\"Hello, MCP!\", resource=\"EchoResource\")\nprint(response)\n</code></pre></p> <p>Run the client: <pre><code>python client.py\n</code></pre></p>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#5-example-registering-tools-and-resources","title":"5. Example: Registering Tools and Resources","text":"<p>Resource: A model, tool, or function exposed via MCP.</p> <p>Example: Calculator Tool <pre><code>from mcp_sdk.resources import ToolResource\n\nclass CalculatorResource(ToolResource):\n    def run(self, input, context):\n        try:\n            return str(eval(input))\n        except Exception as e:\n            return f\"Error: {e}\"\n</code></pre> Register this resource with your server as above.</p>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#6-example-prompt-engineering","title":"6. Example: Prompt Engineering","text":"<p>Prompt: The input you send to a model/tool.</p> <p>Example Prompt for Text Completion: <pre><code>prompt = \"Write a short poem about the ocean.\"\nresponse = client.complete(prompt=prompt, resource=\"TextCompletionResource\")\nprint(response)\n</code></pre></p> <p>Example Prompt for Tool: <pre><code>prompt = \"2 + 2 * 3\"\nresponse = client.run_tool(input=prompt, resource=\"CalculatorResource\")\nprint(response)\n</code></pre></p>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#7-deployment","title":"7. Deployment","text":""},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#a-deploying-the-server","title":"a. Deploying the Server","text":"<ul> <li>Local: As above, just run <code>python server.py</code>.</li> <li>Docker: (if Dockerfile provided)   <pre><code>docker build -t mcp-server .\ndocker run -p 8000:8000 mcp-server\n</code></pre></li> <li>Cloud: Deploy to AWS, GCP, Azure, or Heroku as a standard Python web service.</li> </ul>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#b-deploying-the-client","title":"b. Deploying the Client","text":"<ul> <li>The client can run anywhere with network access to the server.</li> <li>For production, package your client as a CLI, web app, or integrate into your backend.</li> </ul>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#8-resources-tools","title":"8. Resources &amp; Tools","text":"<ul> <li>MCP Python SDK Docs: (Check the official repo or docs site)</li> <li>Example Repos: Look for <code>mcp-python-sdk</code> on GitHub.</li> <li>Prompt Engineering: See <code>docs/ai/prompt-engineering.md</code> in your project.</li> <li>MCP Protocol Overview: See <code>docs/ai/model-context-protocols/overview.md</code> (you can fill this in with the above info).</li> </ul>"},{"location":"ai/model-context-protocols/Sample%20AI-Application-with-MCP/#9-next-steps","title":"9. Next Steps","text":"<ol> <li>Install the SDK as above.</li> <li>Create a server with your own resources/tools.</li> <li>Create a client to interact with your server.</li> <li>Experiment with prompts and tools.</li> <li>Deploy as needed. </li> </ol>"},{"location":"ai/model-context-protocols/use-cases/","title":"MCP Use Cases (Expanded)","text":""},{"location":"ai/model-context-protocols/use-cases/#1-multi-model-ai-assistants","title":"1. Multi-Model AI Assistants","text":"<p>Scenario: You want to build an assistant that can answer general questions, write stories, and solve math problems. You have two LLMs (e.g., GPT-4 for creative tasks, Llama for Q&amp;A) and a calculator tool.</p> <p>How it works: - The MCP server registers each model and tool as a resource. - The client (assistant) routes user requests to the appropriate resource based on intent.</p> <p>Example Flow: 1. User: \"Write a poem about the sea.\"    \u2192 Routed to GPT-4 resource. 2. User: \"What is the capital of France?\"    \u2192 Routed to Llama resource. 3. User: \"Calculate 23 * 47.\"    \u2192 Routed to Calculator tool.</p> <p>Sample Code: <pre><code># Client-side routing logic\nif \"poem\" in user_input:\n    response = client.complete(prompt=user_input, resource=\"GPT4Resource\")\nelif \"capital\" in user_input:\n    response = client.complete(prompt=user_input, resource=\"LlamaResource\")\nelif \"calculate\" in user_input:\n    math_expr = user_input.replace(\"calculate\", \"\").strip()\n    response = client.run_tool(input=math_expr, resource=\"CalculatorResource\")\n</code></pre></p>"},{"location":"ai/model-context-protocols/use-cases/#2-tool-augmented-llms","title":"2. Tool-Augmented LLMs","text":"<p>Scenario: You want your LLM to answer questions and also execute Python code when needed (e.g., for math or data processing).</p> <p>How it works: - The LLM is prompted to call the PythonExecutor tool via MCP when it detects a code execution request.</p> <p>Example Flow: 1. User: \"What is the result of 2**8 + 10?\" 2. LLM: Recognizes this as a computation, sends <code>\"2**8 + 10\"</code> to the PythonExecutor tool. 3. Tool returns <code>266</code>. 4. LLM responds: \"The result is 266.\"</p> <p>Sample Code: <pre><code># Tool resource\nclass PythonExecutorResource(ToolResource):\n    def run(self, input, context):\n        try:\n            return str(eval(input))\n        except Exception as e:\n            return f\"Error: {e}\"\n\n# LLM prompt template\nprompt = (\n    \"If the user asks for a calculation, call the PythonExecutor tool. \"\n    \"Otherwise, answer normally.\\n\"\n    f\"User: {user_input}\"\n)\n</code></pre></p>"},{"location":"ai/model-context-protocols/use-cases/#3-contextual-memory-sharing","title":"3. Contextual Memory Sharing","text":"<p>Scenario: You want the assistant to remember the user's name and preferences across multiple interactions.</p> <p>How it works: - The MCP context object stores user data. - Each resource can access and update the context.</p> <p>Example Flow: 1. User: \"My name is Alice.\"    - Context updated: <code>{\"user_name\": \"Alice\"}</code> 2. User: \"Remind me to call Bob tomorrow.\"    - Context updated: <code>{\"reminders\": [\"call Bob tomorrow\"]}</code> 3. User: \"What's my name?\"    - Assistant retrieves <code>user_name</code> from context and replies: \"Your name is Alice.\"</p> <p>Sample Code: <pre><code># Accessing context in a resource\ndef complete(self, prompt, context):\n    if \"my name\" in prompt:\n        return f\"Your name is {context.get('user_name', 'unknown')}.\"\n    # ... other logic ...\n</code></pre></p>"},{"location":"ai/model-context-protocols/use-cases/#4-agent-frameworks-and-orchestration","title":"4. Agent Frameworks and Orchestration","text":"<p>Scenario: You want to automate a workflow: research a topic, summarize findings, and send an email.</p> <p>How it works: - Each step is handled by a different MCP resource (WebSearch, Summarizer, EmailSender). - An orchestrator client coordinates the workflow.</p> <p>Example Flow: 1. User: \"Research the latest AI trends and email me a summary.\" 2. Orchestrator:    - Calls WebSearch resource for \"latest AI trends\".    - Passes results to Summarizer resource.    - Sends summary to EmailSender resource.</p> <p>Sample Code: <pre><code>search_results = client.run_tool(input=\"latest AI trends\", resource=\"WebSearchResource\")\nsummary = client.complete(prompt=search_results, resource=\"SummarizerResource\")\nclient.run_tool(input=summary, resource=\"EmailSenderResource\")\n</code></pre></p>"},{"location":"ai/model-context-protocols/use-cases/#5-standardized-prompt-engineering","title":"5. Standardized Prompt Engineering","text":"<p>Scenario: You want to ensure all prompts sent to LLMs follow a consistent format for better results.</p> <p>How it works: - Use MCP\u2019s prompt formatting utilities or templates. - Store and reuse prompt templates for different tasks.</p> <p>Example Flow: 1. User: \"Summarize this article.\" 2. Client applies a prompt template: <code>\"Summarize the following text in 3 sentences:\\n{article_text}\"</code> 3. Sends formatted prompt to the LLM resource.</p> <p>Sample Code: <pre><code>prompt_template = \"Summarize the following text in 3 sentences:\\n{content}\"\nformatted_prompt = prompt_template.format(content=article_text)\nresponse = client.complete(prompt=formatted_prompt, resource=\"LLMResource\")\n</code></pre></p>"},{"location":"ai/model-context-protocols/use-cases/#reference","title":"Reference","text":"<p>For more implementation details and code, see Sample AI-Application-with-MCP.md.</p>"},{"location":"blog/2025-06-01-why-event-driven-architecture-scales/","title":"Why Event-Driven Architecture Scales","text":"<p>Event-driven systems respond to events and messages asynchronously.</p>"},{"location":"blog/2025-06-01-why-event-driven-architecture-scales/#benefits","title":"Benefits","text":"<ul> <li>Loose coupling</li> <li>High scalability</li> <li>Real-time processing</li> </ul> <p>Commonly used in modern cloud-native applications.</p>"},{"location":"software-architecture/architectural-views/","title":"Software Architecture","text":""},{"location":"software-architecture/architectural-views/#cmu-sei-three-views","title":"CMU SEI Three Views","text":"<p>The CMU SEI (Software Engineering Institute) Three Views is a classic approach to documenting software architecture. The three views are:</p>"},{"location":"software-architecture/architectural-views/#1-module-view-decomposition-view","title":"1. Module View (Decomposition View)","text":"<ul> <li>What it shows: The static structure of the system in terms of modules (e.g., packages, classes, files).</li> <li>Purpose: Shows how the system is decomposed into implementation units and how these units relate to each other.</li> <li>Audience: Developers, maintainers.</li> <li>Details:      -Shows how the system is broken down into modules (e.g., packages, classes, files).<ul> <li>Focuses on code structure, encapsulation, and dependencies.</li> </ul> </li> <li>Example: A class diagram showing how classes are organized into packages.</li> </ul> <pre><code>classDiagram\n    class AuthModule\n    class UserModule\n    class OrderModule\n    class PaymentModule\n\n    AuthModule &lt;|-- UserModule : uses\n    UserModule &lt;|-- OrderModule : uses\n    OrderModule &lt;|-- PaymentModule : uses</code></pre>"},{"location":"software-architecture/architectural-views/#2-component-and-connector-view-cc-view","title":"2. Component-and-Connector View (C&amp;C View)","text":"<ul> <li>What it shows: The dynamic structure of the system as a set of components (units of computation) and connectors (interaction mechanisms).</li> <li>Purpose: Illustrates how runtime elements interact, such as processes, threads, data flows, and communication paths.</li> <li>Audience: System integrators, testers, performance engineers.</li> <li>Details: <ul> <li>Shows the runtime structure: components (processes, services) and connectors (communication, data flow).</li> <li>Focuses on how parts of the system interact at runtime.</li> </ul> </li> <li>Example: A diagram showing how services communicate over a network.</li> </ul> <pre><code>flowchart LR\n    ClientApp --&gt;|REST API| APIGateway\n    APIGateway --&gt;|gRPC| UserService\n    APIGateway --&gt;|gRPC| OrderService\n    OrderService --&gt;|Event| PaymentService\n    UserService --&gt;|DB| UserDB[(User Database)]\n    OrderService --&gt;|DB| OrderDB[(Order Database)]\n    PaymentService --&gt;|DB| PaymentDB[(Payment Database)]</code></pre>"},{"location":"software-architecture/architectural-views/#3-allocation-view","title":"3. Allocation View","text":"<ul> <li>What it shows: The mapping of software elements to the environment, such as hardware, file systems, or teams.</li> <li>Purpose: Shows how software is deployed, assigned to hardware, or mapped to development teams.</li> <li>Audience: System engineers, deployment engineers, project managers.</li> <li>Details: <ul> <li>Shows how software elements are mapped to hardware, file systems, or teams.</li> <li>Focuses on deployment, physical distribution, or team responsibility.</li> </ul> </li> <li>Example: A deployment diagram mapping software components to servers.</li> </ul> <pre><code>graph TD\n    subgraph AWS_Cloud[Cloud Provider]\n        subgraph VPC[Virtual Private Cloud]\n            subgraph Public_Subnet\n                LB[Load Balancer]\n            end\n            subgraph Private_Subnet\n                App1[App Server 1]\n                App2[App Server 2]\n                DB[(Database Cluster)]\n                Cache[(Redis Cache)]\n            end\n        end\n    end\n\n    Internet --&gt;|HTTPS| LB\n    LB --&gt; App1\n    LB --&gt; App2\n    App1 --&gt; DB\n    App2 --&gt; DB\n    App1 --&gt; Cache\n    App2 --&gt; Cache</code></pre>"},{"location":"software-architecture/architectural-views/#rup-41-views","title":"RUP 4+1 Views","text":"<p>RUP uses the \"4+1\" View Model, which consists of five views:</p>"},{"location":"software-architecture/architectural-views/#1-logical-view","title":"1. Logical View","text":"<ul> <li>What it shows: The object model of the design (e.g., class diagrams).</li> <li>Purpose: Addresses the functionality that the system provides to end-users.</li> <li>Audience: End-users, analysts, designers.</li> <li>Details: <ul> <li>Shows the object model of the design (e.g., class diagrams).</li> <li>Focuses on functionality provided to end-users.</li> </ul> </li> <li>Example: A class diagram showing how classes are organized into packages.</li> </ul> <pre><code>classDiagram\n    class User\n    class Order\n    class Product\n    class ShoppingCart\n\n    User \"1\" -- \"*\" Order : places\n    Order \"*\" -- \"*\" Product : contains\n    User \"1\" -- \"1\" ShoppingCart : owns\n    ShoppingCart \"*\" -- \"*\" Product : holds</code></pre>"},{"location":"software-architecture/architectural-views/#2-development-view-implementation-view","title":"2. Development View (Implementation View)","text":"<ul> <li>What it shows: The static organization of the software in the development environment (e.g., module structure).</li> <li>Purpose: Focuses on software management, configuration, and reuse.</li> <li>Audience: Programmers, software managers.</li> <li>Details: <ul> <li>Shows the static organization of the software in the development environment (e.g., module structure).</li> <li>Focuses on software management, configuration, and reuse.</li> </ul> </li> <li>Example: A class diagram showing how classes are organized into packages.</li> </ul> <pre><code>graph TD\n    subgraph src\n        subgraph controllers\n            UserController\n            OrderController\n        end\n        subgraph services\n            UserService\n            OrderService\n        end\n        subgraph models\n            UserModel\n            OrderModel\n            ProductModel\n        end\n        subgraph repositories\n            UserRepository\n            OrderRepository\n        end\n    end\n\n    UserController --&gt; UserService\n    OrderController --&gt; OrderService\n    UserService --&gt; UserRepository\n    OrderService --&gt; OrderRepository\n    UserService --&gt; UserModel\n    OrderService --&gt; OrderModel\n    OrderModel --&gt; ProductModel</code></pre>"},{"location":"software-architecture/architectural-views/#3-process-view","title":"3. Process View","text":"<ul> <li>What it shows: The dynamic aspects of the system, such as processes and their interactions.</li> <li>Purpose: Addresses concurrency, performance, and scalability.</li> <li>Audience: System integrators, performance engineers.</li> <li>Details: <ul> <li>Shows the dynamic aspects of the system, such as processes and their interactions.</li> <li>Focuses on concurrency, performance, and scalability.</li> </ul> </li> <li>Example: A class diagram showing how classes are organized into packages.</li> </ul> <pre><code>sequenceDiagram\n    participant User\n    participant WebApp\n    participant OrderService\n    participant PaymentGateway\n    participant InventoryService\n\n    User-&gt;&gt;WebApp: Place order\n    WebApp-&gt;&gt;OrderService: Create order\n    OrderService-&gt;&gt;InventoryService: Reserve items\n    OrderService-&gt;&gt;PaymentGateway: Process payment\n    PaymentGateway--&gt;&gt;OrderService: Payment confirmation\n    InventoryService--&gt;&gt;OrderService: Reservation confirmation\n    OrderService-&gt;&gt;WebApp: Order confirmation\n    WebApp-&gt;&gt;User: Show confirmation</code></pre>"},{"location":"software-architecture/architectural-views/#4-physical-view-deployment-view","title":"4. Physical View (Deployment View)","text":"<ul> <li>What it shows: The mapping of software onto hardware and the physical distribution of components.</li> <li>Purpose: Deals with system topology, communication, and deployment.</li> <li>Audience: System engineers, deployment engineers.</li> <li>Details: <ul> <li>Shows the mapping of software onto hardware and the physical distribution of components.</li> <li>Focuses on system topology, communication, and deployment.</li> </ul> </li> <li>Example: A class diagram showing how classes are organized into packages.</li> </ul> <pre><code>flowchart TD\n    subgraph Internet\n        UserClient\n    end\n    subgraph DMZ\n        LB[Load Balancer]\n    end\n    subgraph Web_Tier\n        Web1[Web Server 1]\n        Web2[Web Server 2]\n    end\n    subgraph App_Tier\n        App1[App Server 1]\n        App2[App Server 2]\n    end\n    subgraph Data_Tier\n        DB1[(Primary Database)]\n        DB2[(Replica Database)]\n        FS[(File Storage)]\n        Cache[(Redis Cache)]\n    end\n\n    UserClient --&gt; LB\n    LB --&gt; Web1\n    LB --&gt; Web2\n    Web1 --&gt; App1\n    Web2 --&gt; App2\n    App1 --&gt; DB1\n    App2 --&gt; DB1\n    DB1 --&gt; DB2\n    App1 --&gt; FS\n    App2 --&gt; FS\n    App1 --&gt; Cache\n    App2 --&gt; Cache </code></pre>"},{"location":"software-architecture/architectural-views/#5-use-case-view-1-view","title":"5. Use Case View (\"+1\" View)","text":"<ul> <li>What it shows: The scenarios and use cases that drive the architecture.</li> <li>Purpose: Ties all the other views together by showing how they support the required functionality.</li> <li>Audience: All stakeholders.</li> <li>Details: <ul> <li>Shows the scenarios and use cases that drive the architecture.</li> <li>Focuses on tying all the other views together by showing how they support the required functionality.</li> </ul> </li> <li>Example: A class diagram showing how classes are organized into packages.</li> </ul> <pre><code>flowchart TD\n    User((User)) --&gt;|Login| AuthSystem\n    User --&gt;|Browse| Catalog\n    User --&gt;|Add to Cart| ShoppingCart\n    User --&gt;|Checkout| OrderSystem\n    OrderSystem --&gt;|Payment| PaymentGateway\n    OrderSystem --&gt;|Inventory Check| InventorySystem</code></pre>"},{"location":"software-architecture/architectural-views/#summary-table","title":"Summary Table","text":"Framework View Name Focus/What it Shows CMU SEI Module Static structure (modules, packages) Component-and-Connector Runtime structure (components, connectors) Allocation Mapping to environment (hardware, teams) RUP (4+1) Logical Object model, functionality Development Implementation structure Process Dynamic behavior, concurrency Physical Deployment, hardware mapping Use Case Scenarios, requirements"},{"location":"software-architecture/design-principles/","title":"Design Principles","text":""},{"location":"software-architecture/design-principles/#key-principles","title":"Key Principles","text":"<ul> <li>Separation of Concerns</li> <li>Modularity</li> <li>Encapsulation</li> <li>Loose Coupling &amp; High Cohesion</li> <li>Scalability &amp; Resilience</li> </ul> <p>These principles ensure systems are flexible, testable, and maintainable.</p>"},{"location":"software-architecture/patterns/layered/","title":"Layered Architecture Pattern","text":"<p>Divides systems into layers (e.g., Presentation, Business, Data) with clear responsibilities.</p>"},{"location":"software-architecture/patterns/layered/#benefits","title":"Benefits","text":"<ul> <li>Separation of concerns</li> <li>Easy testing</li> <li>Simplicity</li> </ul>"},{"location":"software-architecture/patterns/layered/#limitations","title":"Limitations","text":"<ul> <li>Tight coupling across layers</li> <li>Performance overhead</li> </ul>"},{"location":"software-architecture/patterns/microservices/","title":"Microservices Pattern","text":"<p>Breaks applications into small, independent services that communicate via APIs.</p>"},{"location":"software-architecture/patterns/microservices/#benefits","title":"Benefits","text":"<ul> <li>Independent deployment</li> <li>Technology heterogeneity</li> <li>Fault isolation</li> </ul>"},{"location":"software-architecture/patterns/microservices/#challenges","title":"Challenges","text":"<ul> <li>Complexity in orchestration</li> <li>Data consistency</li> </ul>"}]}